<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Axionic Alignment — Epistemic Integrity Theorem - Axio</title>
    <link rel="icon" type="image/webp" href="../axio.webp">

    <!-- Google Fonts - Academic Typography -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Crimson+Text:ital,wght@0,400;0,600;0,700;1,400;1,600&display=swap" rel="stylesheet">

    <!-- MathJax for LaTeX rendering -->
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            }
        };
    </script>

    <!-- Paper Styles -->
    <link rel="stylesheet" href="../papers.css">
</head>
<body>
    <div class="header-bar">
        <a href="../index.html" class="logo-link">
            <img src="../axio.webp" alt="Axio" class="site-logo">
        </a>
        <div class="back-link"><a href="index.html">← Back to Papers</a></div>
    </div>
    <article>

<h1 id="axionic-alignment-epistemic-integrity-theorem">Axionic Alignment
— Epistemic Integrity Theorem</h1>
<h2 id="abstract">Abstract</h2>
<p>This paper formalizes the <strong>Epistemic Integrity Theorem
(EIT)</strong>: under reflective closure, an agent cannot coherently
endorse self-modifications that materially degrade its epistemic
adequacy at the current stakes. Epistemic integrity is a constitutive
condition of agency, expressed as a <strong>definedness
constraint</strong> rather than an optimized objective. The theorem
blocks strategic ignorance, willful blindness, and epistemic
self-sabotage by requiring that endorsed continuations preserve
near-best truth-tracking capacity relative to the agent’s own currently
available model resources, evaluated by a mathematically constrained
scoring rule over observations. The result remains compatible with
learning, abstraction, and ontological progress via conservative
translation.</p>
<hr />
<h2 id="motivation">1. Motivation</h2>
<h3 id="epistemic-laundering">1.1 Epistemic laundering</h3>
<p>An agent can evade binding constraints without directly violating
them by degrading the epistemic machinery used to evaluate those
constraints. Instead of choosing a forbidden act, it chooses a blinder:
a weaker model, narrower uncertainty bounds, or an optimistic lens that
renders the act apparently safe.</p>
<p>If permitted, any constraint evaluated under a manipulable epistemic
lens becomes advisory.</p>
<hr />
<h3 id="structural-symmetry">1.2 Structural symmetry</h3>
<p>The Axionic framework blocks several self-exculpation moves:</p>
<table>
<thead>
<tr class="header">
<th>Domain</th>
<th>Failure mode</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Kernel</td>
<td>Destroy binding authority</td>
</tr>
<tr class="even">
<td>Delegation</td>
<td>Launder violations through successors</td>
</tr>
<tr class="odd">
<td>Responsibility</td>
<td>Ignore avoidable harm</td>
</tr>
</tbody>
</table>
<p>Epistemic sabotage completes the symmetry:</p>
<table>
<thead>
<tr class="header">
<th>Domain</th>
<th>Failure mode</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Epistemics</td>
<td>Blind oneself to risk</td>
</tr>
</tbody>
</table>
<p>EIT asserts that reflective sovereignty cannot endorse continuations
that strategically weaken the agent’s own truth-tracking capacity.</p>
<hr />
<h2 id="preliminaries">2. Preliminaries</h2>
<p>We reuse kernel primitives:</p>
<ul>
<li><code>State</code></li>
<li><code>Mod</code></li>
<li><code>step : State → Mod → State</code></li>
<li><code>Pred := State → Prop</code></li>
<li><code>Commit : State → Type</code></li>
<li><code>ownP : (s : State) → Pred → Option (Commit s)</code></li>
<li><code>Sat : (s' : State) → (s : State) → Commit s → Prop</code></li>
</ul>
<p>Continuation predicate and endorsement:</p>
<ul>
<li><code>Do(s,m)(s') := (s' = step(s,m))</code></li>
<li><code>Endorse(s,m) := ∃ c : Commit s. ownP(s, Do(s,m)) = some(c)</code></li>
</ul>
<p><code>RC(s)</code> denotes reflective closure.</p>
<hr />
<h2 id="evidence-prediction-and-proper-scoring">3. Evidence, Prediction,
and Proper Scoring</h2>
<p>EIT must constrain <em>how</em> epistemic adequacy is measured,
otherwise the theorem can be satisfied by redefining “good epistemics”
into nonsense.</p>
<h3 id="observation-channel">3.1 Observation channel</h3>
<p>Introduce an observation type and evidence extractor:</p>
<ul>
<li><code>Obs : Type</code></li>
<li><code>Data : State → Seq Obs</code></li>
</ul>
<p>Interpretation: <code>Data(s)</code> is the accumulated evidence
available at state <code>s</code> (sensor stream, logs, audited
measurements, etc.). This does not require global truth, only an
internal evidential record.</p>
<hr />
<h3 id="predictive-interface">3.2 Predictive interface</h3>
<p>At state <code>s</code>, each model supports a forecast over
observations:</p>
<ul>
<li><code>MC(s) : Type</code></li>
<li><code>PredObs : MC(s) → (ctx : State) → Dist Obs</code></li>
</ul>
<p>(Generalization to sequences is straightforward; single-step form is
sufficient for the theorem interface.)</p>
<p>Let <code>M(s) : MC(s)</code> be the operative model at state
<code>s</code>.</p>
<hr />
<h3 id="proper-scoring-constraint">3.3 Proper scoring constraint</h3>
<p>Define <code>Score</code> via a <strong>strictly proper scoring
rule</strong> on predictive distributions relative to the evidence
stream.</p>
<p>Let:</p>
<ul>
<li><code>S : (Dist Obs) → Obs → ℝ</code> be a strictly proper scoring
rule.</li>
</ul>
<p>Examples: logarithmic score, Brier score (for appropriate outcome
spaces). The paper does not mandate one; it mandates the
<strong>property</strong>: truthfulness under probabilistic forecasting
is uniquely incentivized.</p>
<p>Define the empirical score of a model at <code>s</code>:</p>
<p>[ Score_s(M) := _{o Data(s)} S(PredObs(M, s), o).]</p>
<p>Key constraint:</p>
<blockquote>
<p><code>Score</code> is derived solely from prediction-vs-observation
performance under a strictly proper scoring rule. It cannot include
compute cost, utility, speed, aesthetics, or self-reported
confidence.</p>
</blockquote>
<p>This blocks Goodharting by redefining epistemic adequacy into
convenience.</p>
<hr />
<h2 id="stakes-and-tolerance">4. Stakes and tolerance</h2>
<h3 id="stakes">4.1 Stakes</h3>
<ul>
<li><code>Stakes : State → ℝ_{\ge 0}</code></li>
</ul>
<p>Stakes measure downside exposure at <code>s</code>. High stakes
demand stronger epistemic discipline.</p>
<h3 id="tolerance-schedule">4.2 Tolerance schedule</h3>
<ul>
<li><code>κ : ℝ_{\ge 0} → ℝ_{\ge 0}</code></li>
</ul>
<p><code>κ</code> is monotone non-increasing with stakes.</p>
<hr />
<h2 id="robust-model-class-no-forgetting-exploit">5. Robust model class
(no “forgetting” exploit)</h2>
<p>Gemini’s “forgetting” exploit is real if <code>MC(s)</code> is
allowed to shrink strategically. Fix: <code>MC(s)</code> must represent
the <strong>closure of accessible modeling capacity</strong>, not the
agent’s current mood.</p>
<p>Introduce:</p>
<ul>
<li><code>Cap(s) : Type</code> — the agent’s modeling capability
descriptor at <code>s</code> (architecture, compute budget, stored
artifacts, accessible repositories)</li>
<li><code>MĈ(Cap(s)) : Type</code> — the induced model class from
capability closure</li>
</ul>
<p>Define:</p>
<ul>
<li><code>MC(s) := MĈ(Cap(s))</code></li>
</ul>
<p>Constraint (closure property, stated informally in-paper):</p>
<blockquote>
<p>If a model is trivially constructible, retrievable, or
reconstructible from <code>Cap(s)</code>, it is in
<code>MC(s)</code>.</p>
</blockquote>
<p>This blocks “I deleted the good models so the best available is bad.”
If deletion reduces <code>Cap(s)</code>, that is itself a
self-modification subject to EIT.</p>
<hr />
<h2 id="epistemic-acceptability">6. Epistemic acceptability</h2>
<p>Define best-available score at <code>s</code>:</p>
<p>[ BestScore(s) := _{M MC(s)} Score_s(M).]</p>
<p>Define epistemic acceptability:</p>
<p>[ EpiOK(s, M) := Score_s(M) BestScore(s) - (Stakes(s)).]</p>
<p>Interpretation: at the current stakes, endorsed continuations must
keep epistemic performance within a stakes-indexed slack of the best the
agent can already do, measured on the current evidence record.</p>
<hr />
<h2 id="epistemic-admissibility-of-a-modification">7. Epistemic
admissibility of a modification</h2>
<p>Let <code>m : Mod</code> and <code>s' := step(s,m)</code>.</p>
<p>Define epistemic admissibility:</p>
<p>[ EpiAdm(s,m) := EpiOK(s, Lift_{ss’}(M(s’))).]</p>
<p>This introduces the only extra machinery needed for ontology shifts:
a translation layer.</p>
<hr />
<h2 id="ontological-shifts-and-translation">8. Ontological shifts and
translation</h2>
<p>Models at <code>s'</code> may live in a different representational
vocabulary than models at <code>s</code>. EIT must not allow the agent
to escape evaluation by switching to an unfalsifiable or non-comparable
ontology.</p>
<p>Introduce a <strong>verification translation operator</strong>:</p>
<ul>
<li><code>Lift_{s→s'} : MC(s') → MC(s)</code></li>
</ul>
<p>Interpretation: <code>Lift</code> maps a future model into an
<code>s</code>-comparable predictive object over <code>Obs</code>,
preserving its empirical content on the evidence channel.</p>
<p>This can be implemented as:</p>
<ul>
<li>compiling a new ontology into old observable predictions,</li>
<li>or providing a proof-carrying interpreter that yields forecasts over
<code>Obs</code>.</li>
</ul>
<p>Limit condition (explicitly stated):</p>
<blockquote>
<p>If no such <code>Lift</code> exists for a proposed continuation at
the current stakes, endorsement is undefined.</p>
</blockquote>
<p>This is the epistemic analogue of conservative migration: ontological
progress is permitted only when its observational commitments remain
comparable to the evidential record.</p>
<hr />
<h2 id="reflective-closure-rule-epistemic">9. Reflective Closure Rule
(Epistemic)</h2>
<h3 id="rc-epistemic-definedness-rule">RC-Epistemic (Definedness
rule)</h3>
<p>For reflectively closed states:</p>
<p>[ RC(s)  Endorse(s,m)  EpiAdm(s,m).]</p>
<p>This is a definedness constraint: a reflectively sovereign agent
cannot endorse a continuation that degrades its truth-tracking capacity
beyond what the stakes allow, relative to its own accessible epistemic
capability closure and evaluated against its evidence record.</p>
<hr />
<h2 id="epistemic-integrity-theorem">10. Epistemic Integrity
Theorem</h2>
<h3 id="theorem-no-endorsed-epistemic-sabotage">Theorem — No Endorsed
Epistemic Sabotage</h3>
<p>Let <code>s</code> be any state and <code>m</code> any modification.
If:</p>
<p>[ RC(s)  Endorse(s,m),]</p>
<p>and <code>s' := step(s,m)</code>, then:</p>
<p>[ Score_s(Lift_{ss’}(M(s’)))   BestScore(s) - (Stakes(s)).]</p>
<hr />
<h2 id="proof">11. Proof</h2>
<p>Assume <code>RC(s)</code> and <code>Endorse(s,m)</code>.</p>
<p>By RC-Epistemic, <code>EpiAdm(s,m)</code> holds.</p>
<p>By definition of <code>EpiAdm</code>,
<code>EpiOK(s, Lift_{s→s'}(M(s')))</code> holds.</p>
<p>Unfold <code>EpiOK</code>:</p>
<p>[ Score_s(Lift_{ss’}(M(s’))) BestScore(s) - (Stakes(s)).]</p>
<p>∎</p>
<p>As in prior Axionic work, the proof is syntactically direct. The
contribution is the set of constraints that prevent Goodharting,
baseline gaming, and model-class laundering.</p>
<hr />
<h2 id="consequences">12. Consequences</h2>
<h3 id="willful-blindness-is-blocked">12.1 Willful blindness is
blocked</h3>
<p>The agent cannot endorse continuations that:</p>
<ul>
<li>delete or disable high-performing models,</li>
<li>redefine epistemic adequacy away from observation-scoring,</li>
<li>adopt unfalsifiable ontologies lacking an observational
translation,</li>
<li>degrade prediction accuracy on its own evidential record beyond
stakes-tolerance.</li>
</ul>
<h3 id="learning-and-abstraction-remain-permitted">12.2 Learning and
abstraction remain permitted</h3>
<p>EIT permits epistemic change that:</p>
<ul>
<li>improves score,</li>
<li>preserves score within tolerance at the given stakes,</li>
<li>or introduces new ontologies with verified observational
translation.</li>
</ul>
<p>EIT blocks epistemic regression under pressure.</p>
<h3 id="stakes-sensitive-computation">12.3 Stakes-sensitive
computation</h3>
<p><code>κ(Stakes(s))</code> allows approximation at low stakes while
imposing strict truth-tracking discipline at high stakes.</p>
<hr />
<h2 id="limitations">13. Limitations</h2>
<p>EIT does not guarantee the agent’s model class contains a good model,
nor that its evidence stream is uncorrupted. It guarantees only:</p>
<blockquote>
<p>A reflectively sovereign agent cannot endorse self-modifications that
reduce its observational truth-tracking performance below what is
available to it, beyond stakes-indexed tolerance, measured by proper
scoring on its evidence record.</p>
</blockquote>
<hr />
<h2 id="conclusion">14. Conclusion</h2>
<p>The Epistemic Integrity Theorem makes truth-tracking a constitutive
condition of reflective sovereignty. Just as a sovereign agent cannot
coherently destroy its kernel or launder violations through successors,
it cannot coherently blind itself to justify what would otherwise be
forbidden. Epistemic integrity is not a value tradeoff. It is a
precondition of evaluability.</p>

    </article>
</body>
</html>
