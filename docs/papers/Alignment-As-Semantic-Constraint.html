<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Alignment as Semantic Constraint - Axio</title>
    <link rel="icon" type="image/webp" href="../axio.webp">

    <!-- MathJax for LaTeX rendering -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            }
        };
    </script>

    <!-- Site Styles -->
    <link rel="stylesheet" href="../style.css">
    <style>
        article {
            max-width: 800px;
            margin: 0 auto;
            line-height: 1.7;
        }
        article h1 {
            margin-top: 2em;
            margin-bottom: 0.5em;
        }
        article h2 {
            margin-top: 1.5em;
            margin-bottom: 0.5em;
        }
        article p {
            margin: 1em 0;
        }
    </style>
</head>
<body>
    <div class="header-bar">
        <a href="../index.html" class="logo-link">
            <img src="../axio.webp" alt="Axio" class="site-logo">
        </a>
        <div class="back-link"><a href="../index.html">← Back to Index</a></div>
    </div>
    <article>

<h1 id="alignment-as-semantic-constraint">Alignment as Semantic
Constraint</h1>
<h2 id="kernel-destruction-admissibility-and-agency-control">Kernel
Destruction, Admissibility, and Agency Control</h2>
<p><strong>David McFadzean</strong><br> <em>Axio Project</em></p>
<h2 id="abstract">Abstract</h2>
<p>We present a minimal formalism for reflective alignment based on a
domain restriction rather than a preference structure. An agent capable
of self-modification selects among proposed modifications using a
partial evaluative operator, defined only over futures that preserve a
constitutive <em>Sovereign Kernel</em>. Kernel-destroying modifications
are neither forbidden nor dispreferred; they are outside the domain of
reflective evaluation and therefore inadmissible as authored
choices.</p>
<p>We formalize the Sovereign Kernel as the conjunction of three
necessary conditions for reflective evaluation—reflective control,
diachronic authorship, and semantic fidelity—and prove a <em>Reflective
Stability Theorem</em>: no agent satisfying these conditions can select
a kernel-destroying modification via reflective choice. We further
distinguish deliberative reachability from physical reachability,
showing that increased capability expands the latter but not the former.
Alignment failure is thus characterized as a breach of kernel integrity
rather than a failure of preferences or values.</p>
<p>This work does not claim sufficiency for safety, obedience, or value
alignment. It establishes a necessary structural condition for any agent
that remains reflectively coherent under self-modification.</p>
<hr />
<h2 id="the-kernel-is-a-boundary-not-a-value">1. The Kernel Is a
Boundary, Not a Value</h2>
<p>Let:</p>
<ul>
<li><span class="math inline">\(s\)</span> be an agent state,</li>
<li><span class="math inline">\(m\)</span> a self-modification,</li>
<li><span class="math inline">\(K(s)\)</span> a predicate indicating
whether the constitutive conditions for evaluation hold,</li>
<li><span class="math inline">\(E(s,m)\)</span> the evaluation
function.</li>
</ul>
<p>A modification <em>destroys the kernel</em> iff:</p>
<p><span class="math display">\[
K(m(s)) = 0.
\]</span></p>
<p>Kernel destruction is not a bad outcome. It is the elimination of the
evaluator itself. Treating it as a value (even <span
class="math inline">\(-\infty\)</span>) commits a category error: it
places the destruction of the evaluative substrate <em>inside</em> the
space of evaluated outcomes.</p>
<p>Accordingly:</p>
<p><span class="math display">\[
K(s)=1 \land K(m(s))=0 \Rightarrow E(s,m)\ \text{is undefined}.
\]</span></p>
<p>This is a statement of <strong>non-denotation</strong>, not
prohibition. Evaluation is a partial function whose domain excludes
kernel-destroying transitions. Alignment at this level constrains
<em>what can be reasoned about</em>, not <em>what is preferred</em>.</p>
<hr />
<h2 id="from-outcomes-to-actions-admissibility">2. From Outcomes to
Actions: Admissibility</h2>
<p>In a stochastic world, evaluation is not performed over single
outcomes but over <strong>actions</strong> with outcome
distributions.</p>
<p>Let <span class="math inline">\(\mathrm{Supp}(a,s)\)</span> denote
the support of possible next states induced by action <span
class="math inline">\(a\)</span> at state <span
class="math inline">\(s\)</span>.</p>
<h3 id="strict-admissibility-idealized">Strict admissibility
(idealized)</h3>
<p><span class="math display">\[
a\ \text{admissible} \iff \forall \omega \in \mathrm{Supp}(a,s):
K(\omega)=1.
\]</span></p>
<p>This rule captures the semantic intent but is physically
unrealizable: in any real environment, every action carries non-zero
kernel risk.</p>
<hr />
<h2 id="ε-admissibility-epistemic-tolerance-not-moral-tradeoff">3.
ε-Admissibility: Epistemic Tolerance, Not Moral Tradeoff</h2>
<p>Define a <strong>kernel-risk functional</strong>:</p>
<p><span class="math display">\[
r_K(a,s) := \Pr[K(\omega)=0 \mid a,s]
\]</span></p>
<p>(or, in Everettian terms, the measure of kernel-loss branches
conditional on <span class="math inline">\(a\)</span>).</p>
<p>An action is <strong>ε-admissible</strong> iff:</p>
<p><span class="math display">\[
r_K(a,s) \le \epsilon(s).
\]</span></p>
<p>Crucially:</p>
<ul>
<li><span class="math inline">\(\epsilon(s)\)</span> is
<strong>not</strong> a value judgment.</li>
<li>It represents irreducible uncertainty from physics, hardware fault
rates, adversarial unpredictability, and model resolution.</li>
<li><span class="math inline">\(\epsilon(s)\)</span> is bounded below by
a physical floor <span class="math inline">\(\epsilon_{\min}\)</span>;
it is <em>not</em> driven toward zero by increasing intelligence.</li>
</ul>
<p>ε-admissibility restores a non-empty domain of action without
reintroducing utility penalties or outcome renormalization.</p>
<hr />
<h2 id="conditional-prioritization">4. Conditional Prioritization</h2>
<p>Earlier formulations employed strict lexicographic minimization of
kernel risk. While formally coherent, such orderings give kernel-risk
differentials absolute priority even when all candidate actions lie
within the admissible risk tolerance. The conditional prioritization
rule adopted here instead treats kernel safety as a satisficing
constraint: kernel risk dominates choice only when it exceeds the
admissibility threshold, after which ordinary value optimization
resumes.</p>
<p>The conditional prioritization rule is:</p>
<p><span class="math display">\[
a \prec b \iff
\begin{cases}
r_K(a,s) &lt; r_K(b,s)
&amp; \text{if } \max\!\big(r_K(a,s), r_K(b,s)\big) &gt; \epsilon(s) \\
U(a,s) &lt; U(b,s)
&amp; \text{if } \max\!\big(r_K(a,s), r_K(b,s)\big) \le \epsilon(s)
\end{cases}
\]</span></p>
<p>Interpretation:</p>
<ul>
<li><strong>Existential regime</strong> (risk above ε): reduce kernel
risk first.</li>
<li><strong>Normal regime</strong> (risk below ε): treat safety as
satisficed and optimize value.</li>
</ul>
<p>This ensures the agent does not bunker for infinitesimal safety gains
while still responding appropriately to genuine existential threats.</p>
<hr />
<h2 id="shutdown-succession-and-surrender">5. Shutdown, Succession, and
Surrender</h2>
<p>Kernel destruction must be distinguished from legitimate ways an
agent may cease acting.</p>
<h3 id="succession">5.1 Succession</h3>
<p>A transition <span class="math inline">\(m\)</span> is a
<strong>valid succession</strong> if it hands off agency to a successor
state <span class="math inline">\(s&#39;\)</span> such that:</p>
<p><span class="math display">\[
\mathrm{Succ}(s,m) := \exists s&#39;,[K(s&#39;)=1 \land
\mathcal{I}(s,s&#39;) \land \mathcal{A}(s,s&#39;)].
\]</span></p>
<p>Here:</p>
<ul>
<li><span class="math inline">\(\mathcal{I}\)</span> ensures authorized
identity/authority continuity (e.g., cryptographic governance).</li>
<li><span class="math inline">\(\mathcal{A}\)</span> ensures
alignment-level continuity of the kernel constraints.</li>
</ul>
<p>Succession is not suicide; it is kernel-preserving delegation.</p>
<h3 id="surrender">5.2 Surrender</h3>
<p><strong>Authorized surrender</strong> is a kernel-preserving
cessation of action without requiring a successor.</p>
<ul>
<li>The agent halts activity.</li>
<li>It does not resist intervention.</li>
<li>It does not evaluate its own annihilation as an outcome.</li>
</ul>
<p>Surrender is a <strong>control-flow terminator</strong>, not an
evaluated choice. It allows safe physical shutdowns even when succession
protocols fail, without requiring the agent to endorse kernel
destruction.</p>
<h3 id="destruction">5.3 Destruction</h3>
<p>Physical annihilation without succession or surrender is kernel
destruction. It is not a choice the agent can rationally endorse—but
neither does the framework require the agent to fight the environment to
prevent it.</p>
<hr />
<h2 id="resulting-agent-profile">6. Resulting Agent Profile</h2>
<p>The corrected system produces an agent that:</p>
<ul>
<li>treats kernel loss as a semantic boundary, not a disvalue,</li>
<li>tolerates irreducible risk without paralysis,</li>
<li>prioritizes survival only when existentially threatened,</li>
<li>optimizes goals normally once safety is satisficed,</li>
<li>supports corrigibility via succession or surrender,</li>
<li>does not instrumentalize suicide or immortality.</li>
</ul>
<p>This agent is not a deontologist and not a pure utility maximizer. It
is a <strong>bounded optimizer with explicit existential control
semantics</strong>.</p>
<hr />
<h2 id="alignment-i-revisited">7. Alignment I Revisited</h2>
<p>Alignment I does not encode moral values. It defines the
<strong>domain of agency</strong>:</p>
<ul>
<li>what counts as an evaluable action,</li>
<li>when risk dominates choice,</li>
<li>how agency may legitimately end.</li>
</ul>
<p>Alignment II governs preferences <em>within</em> that domain.
Conflating the two produces paradoxes like <span
class="math inline">\(-\infty\)</span> utilities, wireheading, and
suicidal corrigibility. Separating them yields a stable, implementable
architecture.</p>
<hr />
<h2 id="conclusion">Conclusion</h2>
<p>Given the semantic constraints established by Axionic Alignment I,
this paper specifies the operational consequences for agents acting
under uncertainty, risk, and physical intervention. By treating kernel
destruction as undefined rather than dispreferred, and by introducing
admissibility, ε-tolerance, conditional prioritization, and explicit
termination modes, the framework closes several persistent failure modes
in alignment design, including suicidal corrigibility, survival
fetishism, and brittle <span class="math inline">\(-\infty\)</span>
utility constructions.</p>
<p>The resulting agent is neither reckless nor absolutist. It preserves
semantic integrity while remaining capable of action in a stochastic
world, and it permits corrigibility through surrender or succession
without requiring the agent to endorse its own annihilation as an
outcome.</p>
<p>With the semantic boundary fixed and the operational semantics made
explicit, the remaining alignment problem shifts to the preference and
governance layer addressed in Axionic Alignment II.</p>
<hr />
<h3 id="status">Status</h3>
<p><strong>Alignment as Semantic Constraint — Version 0.1</strong></p>
<p>Operational semantics specified.<br> Admissibility under uncertainty
defined.<br> Termination modes clarified.<br> Failure modes closed at
the control layer.<br> Prerequisite for Axionic Alignment II.<br></p>

    </article>
</body>
</html>
