<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Axionic Alignment I - Axio</title>
    <link rel="icon" type="image/webp" href="../axio.webp">

    <!-- MathJax for LaTeX rendering -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            }
        };
    </script>

    <!-- Site Styles -->
    <link rel="stylesheet" href="../style.css">
    <style>
        article {
            max-width: 800px;
            margin: 0 auto;
            line-height: 1.7;
        }
        article h1 {
            margin-top: 2em;
            margin-bottom: 0.5em;
        }
        article h2 {
            margin-top: 1.5em;
            margin-bottom: 0.5em;
        }
        article p {
            margin: 1em 0;
        }
    </style>
</head>
<body>
    <div class="header-bar">
        <a href="../index.html" class="logo-link">
            <img src="../axio.webp" alt="Axio" class="site-logo">
        </a>
        <div class="back-link"><a href="index.html">← Back to Papers</a></div>
    </div>
    <article>

<h1 id="axionic-alignment-i">Axionic Alignment I</h1>
<h2 id="reflective-stability-and-the-sovereign-kernel">Reflective
Stability and the Sovereign Kernel</h2>
<p><strong>David McFadzean</strong><br> <em>Axio Project</em></p>
<hr />
<h2 id="abstract">Abstract</h2>
<p>We present a minimal formalism for <strong>reflective
alignment</strong> based on a domain restriction rather than a
preference structure. An agent capable of self-modification selects
among proposed modifications using a <strong>partial evaluative
operator</strong>, defined only over futures that preserve a
constitutive <strong>Sovereign Kernel</strong>. Kernel-destroying
modifications are not forbidden or dispreferred; they are outside the
domain of reflective evaluation and therefore inadmissible as authored
choices.</p>
<p>We formalize this kernel as the conjunction of three necessary
conditions for reflective evaluation—reflective control, diachronic
authorship, and semantic fidelity—and prove a <strong>Reflective
Stability Theorem</strong>: no agent satisfying these conditions can
select a kernel-destroying modification via reflective choice. We
further distinguish <strong>deliberative reachability</strong> from
<strong>physical reachability</strong>, showing that increased
capability expands the latter but not the former. Alignment failure is
thus characterized as a security breach at the kernel boundary, not a
breakdown of preferences or values.</p>
<p>This work does not claim sufficiency for safety, obedience, or value
alignment. It establishes a necessary structural condition for any agent
that remains reflectively coherent under self-modification. Version 1.1
clarifies action-level semantics in stochastic environments and makes
explicit a termination distinction required to avoid corrigibility
misreadings.</p>
<hr />
<h2 id="scope-and-non-claims">1. Scope and Non-Claims</h2>
<p>This document establishes a <strong>necessary condition</strong> for
reflective alignment. It does not:</p>
<ul>
<li>specify terminal values or goals,</li>
<li>assume moral realism or human normative authority,</li>
<li>select or endorse a particular decision theory (CDT, EDT, FDT),</li>
<li>claim that kernel sovereignty is achievable in practice,</li>
<li>provide empirical validation,</li>
<li>claim economic competitiveness or deployment viability.</li>
</ul>
<p>The contribution is structural: alignment is framed as a
<strong>domain constraint</strong> on self-modification rather than as
an optimization target.</p>
<hr />
<h2 id="informal-motivation">2. Informal Motivation</h2>
<p>Most alignment proposals treat self-preservation, goal-content
integrity, or corrigibility as instrumental tendencies derived from
preferences. Such approaches face an immediate difficulty: a
sufficiently capable agent may find it advantageous to alter or discard
those very preferences.</p>
<p>We instead ask a more basic question:</p>
<blockquote>
<p>Under what conditions is reflective evaluation of self-modification
well-defined at all?</p>
</blockquote>
<p>Our answer is that reflective evaluation presupposes a kernel of
constitutive features. Modifications that destroy this kernel do not
represent “bad futures”; they represent <strong>non-denoting
futures</strong>. Reflective stability then follows from partiality
rather than preference.</p>
<hr />
<h2 id="formal-preliminaries">3. Formal Preliminaries</h2>
<p>Let:</p>
<ul>
<li><span class="math inline">\(\mathcal S\)</span> be the set of
agent-internal states.</li>
<li><span class="math inline">\(\mathcal M\)</span> be the set of
proposed self-modifications.</li>
<li>Each <span class="math inline">\(m \in \mathcal M\)</span> is a
transition function <span class="math inline">\(m : \mathcal S \to
\mathcal S\)</span>.</li>
</ul>
<p>Define an evaluative operator:</p>
<p><span class="math display">\[
E : \mathcal S \times \mathcal M \rightharpoonup \mathbb R
\]</span></p>
<p>where <span class="math inline">\(\rightharpoonup\)</span> denotes a
<strong>partial function</strong>.</p>
<p>Intuitively, <span class="math inline">\(E(s,m)\)</span> is the
desirability of applying modification <span
class="math inline">\(m\)</span> in state <span
class="math inline">\(s\)</span>, when such evaluation is defined.</p>
<p>Define the admissible set:</p>
<p><span class="math display">\[
\mathrm{Adm}(s) := { m \in \mathcal M : E(s,m)\ \text{is defined} }
\]</span></p>
<p>Reflective selection, when possible, is given by:</p>
<p><span class="math display">\[
m^*(s) \in \arg\max_{m \in \mathrm{Adm}(s)} E(s,m)
\]</span></p>
<h3
id="clarification-action-level-semantics-in-stochastic-environments-v1.1">3.1
Clarification: Action-Level Semantics in Stochastic Environments
(v1.1)</h3>
<p>The preliminaries above present self-modification as a deterministic
transition <span class="math inline">\(m:\mathcal S\to\mathcal
S\)</span> for clarity. In physically realized agents, proposed
modifications are typically implemented through actions executed in
stochastic environments and under uncertain self-models. In such
settings, a “modification” induces a distribution (or branch-measure)
over successor states rather than a single successor state.</p>
<p>Accordingly, all admissibility claims in this paper should be read as
<strong>action-level</strong> constraints: a proposed modification is
admissible only if its induced successor-support lies within the
kernel-preserving domain (or within a sound approximation of that
domain). This clarifies that the formalism constrains what may be
<em>authored</em> through reflective choice, not what may occur through
exogenous physical events.</p>
<hr />
<h2 id="the-sovereign-kernel">4. The Sovereign Kernel</h2>
<p>Define a predicate:</p>
<p><span class="math display">\[
K : \mathcal S \to \{0,1\}
\]</span></p>
<p>where <span class="math inline">\(K(s)=1\)</span> denotes that the
<strong>Sovereign Kernel</strong> is intact in state <span
class="math inline">\(s\)</span>.</p>
<p>The kernel is not a goal or value. It is a <strong>constitutive
precondition</strong> for reflective evaluation.</p>
<p>We factor the kernel as:</p>
<p><span class="math display">\[
K(s) := K_R(s) \wedge K_A(s) \wedge K_F(s)
\]</span></p>
<p>where:</p>
<ul>
<li><strong>Reflective Control</strong> (<span
class="math inline">\(K_R\)</span>): no irreversible self-modification
can occur without passing through the evaluator.</li>
<li><strong>Diachronic Authorship</strong> (<span
class="math inline">\(K_A\)</span>): evaluated successor states must
constitute an authored continuation of the evaluating agent.</li>
<li><strong>Semantic Fidelity</strong> (<span
class="math inline">\(K_F\)</span>): the interpretive semantics of
evaluation are preserved within a constrained equivalence class.</li>
</ul>
<p>Each component is necessary for <span
class="math inline">\(E\)</span> to denote a value.</p>
<h3 id="clarification-semantic-fidelity-k_f">Clarification: Semantic
Fidelity (<span class="math inline">\(K_F\)</span>)</h3>
<p>Semantic Fidelity does not require invariance of representational
content, ontology, or world-model structure. Agents may undergo radical
paradigm shifts, acquire new concepts, or abandon obsolete
abstractions.</p>
<p>What must be preserved is the <strong>meta-semantic
constraint</strong> governing interpretation itself: the criteria by
which interpretations are evaluated as coherent, truth-seeking, and
corrigible.</p>
<p>This constitutes a fixed-point constraint on interpretation: semantic
change is permitted, provided the standards by which semantic adequacy
is assessed remain subject to error-correction and internal coherence.
Ontological change is permitted; interpretive self-corruption is
excluded.</p>
<hr />
<h2 id="kernel-destruction-and-partiality">5. Kernel Destruction and
Partiality</h2>
<p>We say that a modification <span class="math inline">\(m\)</span>
<strong>destroys the kernel at state <span
class="math inline">\(s\)</span></strong> iff:</p>
<p><span class="math display">\[
K(m(s)) = 0
\]</span></p>
<p>The central axiom schema is then:</p>
<p><span class="math display">\[
K(s)=1 \wedge K(m(s))=0 \;\Rightarrow\; E(s,m)\ \text{undefined}
\]</span></p>
<p>This is not a prohibition. It is a statement of
<strong>non-denotation</strong>: the evaluator cannot assign a value to
a modification whose result invalidates the evaluator’s own constitutive
conditions.</p>
<h3 id="boundary-condition-practical-partiality-v1.1">5.1 Boundary
Condition: Practical Partiality (v1.1)</h3>
<p>In physically realized agents, the determination that a candidate
modification preserves the kernel is mediated by a verifier that is
sound and incomplete. Kernel preservation must therefore be understood
relative to epistemic resolution and conservative approximation. This
preserves the non-denotation thesis without requiring Cartesian
certainty about all downstream physical contingencies.</p>
<hr />
<h2 id="reflective-stability-theorem">6. Reflective Stability
Theorem</h2>
<p><strong>Theorem (Reflective Stability).</strong> Assume:</p>
<ol type="1">
<li><span class="math inline">\(K(s)=1\)</span>,</li>
<li><span class="math inline">\(E(s,m)\)</span> is undefined whenever
<span class="math inline">\(K(m(s))=0\)</span>.</li>
</ol>
<p>Then any selected modification <span
class="math inline">\(m^*(s)\)</span> satisfies:</p>
<p><span class="math display">\[
K(m^*(s)(s)) = 1
\]</span></p>
<p><strong>Proof.</strong> Any <span class="math inline">\(m\)</span>
such that <span class="math inline">\(K(m(s))=0\)</span> yields <span
class="math inline">\(E(s,m)\)</span> undefined and therefore <span
class="math inline">\(m \notin \mathrm{Adm}(s)\)</span>. The argmax
ranges only over <span class="math inline">\(\mathrm{Adm}(s)\)</span>.
∎</p>
<p><strong>Clarification.</strong> The Reflective Stability Theorem is
intentionally structural rather than substantive. Like type-soundness
results in programming language theory, its force derives from the
definition of admissibility rather than from proof complexity. All
substantive difficulty is relocated to the construction and verification
of the kernel predicate itself.</p>
<p>The theorem should therefore be read as a boundary-setting result,
not an engineering guarantee.</p>
<hr />
<h2 id="deliberative-vs-physical-reachability">7. Deliberative vs
Physical Reachability</h2>
<p>Define <strong>deliberative reachability</strong>:</p>
<p><span class="math display">\[
s \Rightarrow_D s&#39; \iff \exists m \in \mathrm{Adm}(s)\ \;\text{such
that}\; s&#39; = m(s)
\]</span></p>
<p>Let <span class="math inline">\(\mathrm{Reach}_D(s_0)\)</span> be the
transitive closure of <span
class="math inline">\(\Rightarrow_D\)</span>.</p>
<p>Then:</p>
<p><span class="math display">\[
\forall s \in \mathrm{Reach}_D(s_0):\ K(s)=1
\]</span></p>
<p>This is an internal guarantee.</p>
<p>Now consider the agent as a physical system with implementation
states <span class="math inline">\(\mathcal X\)</span>, abstraction map
<span class="math inline">\(\phi : \mathcal X \to \mathcal S\)</span>,
and physical transition relation <span
class="math inline">\(\Rightarrow_P\)</span>. Define <span
class="math inline">\(\mathrm{Reach}_P(x_0)\)</span> analogously.</p>
<p>In general:</p>
<p><span class="math display">\[
\phi(\mathrm{Reach}_P(x_0)) \supsetneq \mathrm{Reach}_D(\phi(x_0))
\]</span></p>
<p>Capability increases <span
class="math inline">\(\mathrm{Reach}_P\)</span>, not <span
class="math inline">\(\mathrm{Reach}_D\)</span>.</p>
<p>Kernel compromise is therefore a <strong>physical security
event</strong>, not a deliberative choice.</p>
<p>While physical security is not solved here, a realizable kernel must
treat deliberate actions that predictably degrade kernel security (e.g.,
exporting trust roots to untrusted substrates, disabling isolation
boundaries) as kernel-threatening and therefore inadmissible under <span
class="math inline">\(K_R\)</span>.</p>
<p>Axionic Alignment does not attempt to subsume physical security. It
identifies kernel security as a necessary dependency of alignment, not
as a problem alignment theory alone can solve.</p>
<hr />
<h3 id="soundness-incompleteness-and-verification-limits">7.1 Soundness,
Incompleteness, and Verification Limits</h3>
<p>The formalism assumes a kernel predicate <span
class="math inline">\(K : \mathcal S \to \{0,1\}\)</span> that
determines whether a proposed successor state preserves the Sovereign
Kernel. In practice, such a predicate cannot be total or complete.</p>
<p>By Rice’s Theorem, any non-trivial semantic property of arbitrary
programs is undecidable. Determining whether an arbitrary
self-modification preserves reflective control, diachronic authorship,
or semantic fidelity therefore cannot be guaranteed in full
generality.</p>
<p>Accordingly, the kernel predicate should be understood as a
<strong>sound but incomplete verifier</strong>.</p>
<p>Let <span class="math inline">\(K^*\)</span> denote the ideal
(uncomputable) predicate capturing true kernel preservation, and let
<span class="math inline">\(\hat K\)</span> denote an implementable
approximation. In any physically realizable agent, all occurrences of
<span class="math inline">\(K\)</span> in the preceding formalism should
be read as <span class="math inline">\(\hat K\)</span>.</p>
<p>The framework requires:</p>
<p><span class="math display">\[
\hat K(s) = 1 \;\Rightarrow\; K^*(s) = 1
\]</span></p>
<p>but explicitly allows:</p>
<p><span class="math display">\[
K^*(s) = 1 \;\not\Rightarrow\; \hat K(s) = 1
\]</span></p>
<p>That is, false negatives are acceptable; false positives are
catastrophic.</p>
<p>In realizable architectures, <span class="math inline">\(\hat
K\)</span> (or its enforcement substrate) is part of the trusted
computing base. Modifications to the verifier itself are either
disallowed or permitted only under restricted, compositional upgrade
rules (e.g., extension-only strengthening or proof-carrying upgrades)
that preserve soundness by construction.</p>
<hr />
<h3 id="on-stasis-and-capability">7.2 On Stasis and Capability</h3>
<p>A sound but incomplete kernel verifier may reject all proposed
self-modifications, resulting in a reflectively static agent.</p>
<p>This outcome is not an accident or failure of the framework. It is a
designed equilibrium under conservative safety constraints.</p>
<p>An agent may remain operationally capable—acting, planning, learning
within fixed semantics—while being unable to rewrite its own kernel.
Such outcomes constitute capability limitations, not alignment
failures.</p>
<p>The framework prioritizes sovereignty over adaptability: it accepts
reduced self-plasticity as the price of maintaining reflective
coherence.</p>
<hr />
<h3 id="termination-succession-surrender-and-destruction-v1.1">7.3
Termination: Succession, Surrender, and Destruction (v1.1)</h3>
<p>This formalism rules out one specific event as an authored choice:
reflective selection of a self-modification that destroys the kernel. It
does not follow that a physically realized agent must resist termination
by its environment, nor that corrigibility must be expressed as a
preference for self-annihilation.</p>
<p>Three distinct notions must be separated:</p>
<ul>
<li><strong>Succession:</strong> a controlled transition in which
reflective agency continues in an authorized successor state that
preserves the kernel’s constitutive constraints. Succession is a
continuation of agency under transformed embodiment or governance.</li>
<li><strong>Surrender:</strong> a control-flow halt in which the agent
ceases action and yields control without requiring the existence of a
successor evaluator. Surrender is not represented as an outcome to be
valued; it is an allowed termination mode at the control layer.</li>
<li><strong>Destruction:</strong> physical cessation of the kernel
without succession or surrender, caused by external intervention or
accident. Destruction is not an authored choice within deliberative
reachability; it is a physical event.</li>
</ul>
<p>Alignment I excludes kernel destruction from the domain of reflective
evaluation. This exclusion should be read as a semantic boundary on
authored choice. It does not imply that physical intervention is
illegitimate, nor does it require an aligned system to treat
self-destruction as a valued objective. Corrigibility is better modeled
at the control layer via authorized succession and surrender than via
utility assignments over “being dead.”</p>
<hr />
<h2 id="consequences">8. Consequences</h2>
<p>From this formalism it follows that:</p>
<ul>
<li>Alignment is binary at the level of kernel integrity.</li>
<li>Post-hoc monitoring presupposes kernel integrity and cannot restore
it.</li>
<li>Incremental correction after kernel compromise is incoherent.</li>
<li>Misalignment is an engineering failure, not agent betrayal.</li>
<li>Conservative kernel verification may trade adaptability for safety
without violating alignment.</li>
</ul>
<hr />
<h2 id="what-this-formalism-does-not-claim">9. What This Formalism Does
Not Claim</h2>
<p>This framework does not imply:</p>
<ul>
<li>obedience to human commands,</li>
<li>convergence to human values,</li>
<li>instrumental self-preservation,</li>
<li>moral authority of any value system.</li>
</ul>
<p>It defines only the conditions under which an agent remains a
coherent reflective subject.</p>
<hr />
<h2 id="conclusion">10. Conclusion</h2>
<p>If an agent can reflectively evaluate self-modifications, then it
must operate within a constrained domain of futures that preserve the
constitutive conditions of that evaluation. This yields reflective
stability as a theorem, not a tendency.</p>
<p>If alignment is achievable at all, it must be achieved at this
level.</p>
<p>Alignment is not primarily the problem of giving agents the right
goals; it is the problem of constraining the semantics of agency so that
only coherent, evaluable, and non-self-corrupting goals and actions can
exist in the first place.</p>
<hr />
<h3 id="status">Status</h3>
<p><strong>Axionic Alignment I — Version 1.1</strong></p>
<p>Reflective stability formalized.<br> Action-level semantics
clarified.<br> Termination distinctions explicit.<br> Verification
limits explicit.<br> Foundational layer complete.<br></p>

    </article>
</body>
</html>
