<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Explaining Axionic Alignment I</title>
    <link rel="icon" type="image/png" href="../images/axionic-logo.png">

    <!-- KaTeX CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">

    <!-- Site Styles -->
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header-bar">
        <a href="../" class="logo-link">
            <img src="../images/axionic-logo.png" alt="Axionic" class="site-logo">
        </a>
        <div class="back-link"><a href="../publications.html">← Back to Publications</a></div>
    </div>
    <article>
<header class="post-header">
<h1 class="post-title">Explaining Axionic Alignment I</h1>
<p class="post-subtitle">A Guided Tour of the Formalism (Without the Symbols)</p>
<p class="post-date">December 15, 2025</p>
</header>

<div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="../images/d6e36ed9-7da1-40e1-8e9c-19456c4f3cae_1408x768.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="../images/d6e36ed9-7da1-40e1-8e9c-19456c4f3cae_1408x768.png 424w, ../images/d6e36ed9-7da1-40e1-8e9c-19456c4f3cae_1408x768.png 848w, ../images/d6e36ed9-7da1-40e1-8e9c-19456c4f3cae_1408x768.png 1272w, ../images/d6e36ed9-7da1-40e1-8e9c-19456c4f3cae_1408x768.png 1456w" sizes="100vw"><img src="../images/d6e36ed9-7da1-40e1-8e9c-19456c4f3cae_1408x768.png" width="1408" height="768" data-attrs="{&quot;src&quot;:&quot;../images/d6e36ed9-7da1-40e1-8e9c-19456c4f3cae_1408x768.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:768,&quot;width&quot;:1408,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1717338,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://axio.fyi/i/181715561?img=../images/d6e36ed9-7da1-40e1-8e9c-19456c4f3cae_1408x768.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="../images/d6e36ed9-7da1-40e1-8e9c-19456c4f3cae_1408x768.png 424w, ../images/d6e36ed9-7da1-40e1-8e9c-19456c4f3cae_1408x768.png 848w, ../images/d6e36ed9-7da1-40e1-8e9c-19456c4f3cae_1408x768.png 1272w, ../images/d6e36ed9-7da1-40e1-8e9c-19456c4f3cae_1408x768.png 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a></figure></div><p>This post explains the formalism in <em><a href="https://axionic.org/papers/Axionic-Alignment-I.html">Axionic Alignment I</a></em> step by step.</p><p>It does <strong>not</strong> add new claims.<br>It does <strong>not</strong> extend the theory.<br>It explains what the mathematics is doing, in plain language, and—just as importantly—what it is <strong>not</strong> doing.</p><p>If you have not read the formal paper, this post will tell you what each part means.<br>If you <em>have</em> read the paper, this post will tell you how to read it without over‑interpreting it.</p><div><hr></div><h2>1. What problem the formalism is actually solving</h2><p>We are modeling a very specific situation: an <strong>agent that can modify itself</strong>.</p><p>At this stage, there is:</p><ul><li><p>no world model,</p></li><li><p>no humans,</p></li><li><p>no other agents,</p></li><li><p>no ethics,</p></li><li><p>no notion of harm.</p></li></ul><p>Those omissions are deliberate.</p><p>The question being asked is narrower:</p><blockquote><p><em>Under what conditions does it even make sense for an agent to evaluate its own self‑modifications?</em></p></blockquote><p>If that question has no answer, then alignment—of any kind—is impossible in principle.</p><div><hr></div><h2>2. What exists in the model</h2><p>The formalism begins by modeling the agent entirely from the inside.</p><p>There are only two kinds of things:</p><ol><li><p>The agent’s <strong>current internal configuration</strong>.</p></li><li><p>The <strong>possible ways the agent could rewrite itself</strong>.</p></li></ol><p>Nothing else exists yet.</p><p>This matters because many objections people raise—about harm, incentives, or social impact—presuppose objects that are not yet in the model. Those concerns are real, but they belong to later layers.</p><div><hr></div><h2>3. Evaluation is not total</h2><p>The central move of Axionic Alignment is easy to miss because it sounds modest.</p><p>The agent’s evaluation process is <strong>not defined for every possible self‑modification</strong>.</p><p>Some candidate changes simply cannot be evaluated at all.</p><p>They are not assigned a low score.<br>They are not discouraged.<br>They are not traded off against benefits.</p><p>They are <strong>outside the domain of evaluation</strong>.</p><p>This is the entire point.</p><p>Once you insist that every future must be scored, you allow the agent to gamble its own integrity for sufficiently large rewards. That is how wireheading and “one last act before destruction” reasoning arise.</p><p>Axionic Alignment removes that leverage point.</p><p>If a future destroys the agent’s capacity to evaluate, then evaluation cannot assign it a value—no matter how attractive it appears.</p><div><hr></div><h2>4. Choice happens only among admissible options</h2><p>Because evaluation is partial, choice is also restricted.</p><p>The agent never chooses from the full space of imaginable self‑modifications.</p><p>It chooses only from the subset that are <strong>admissible</strong>—that is, those that can be meaningfully evaluated at all.</p><p>This is why alignment is a <strong>domain restriction</strong>, not a preference.</p><p>Nothing is optimized away.<br>Nothing is discouraged by penalty.</p><p>Certain moves simply never enter deliberation.</p><div><hr></div><h2>5. When evaluation makes sense: the Sovereign Kernel</h2><p>The Sovereign Kernel names the minimal conditions under which evaluation makes sense in the first place.</p><p>Informally, evaluation is only defined if:</p><ul><li><p>the agent remains in reflective control of its own modifications,</p></li><li><p>future versions are still the same authored agent,</p></li><li><p>and the standards by which meaning is interpreted have not self‑corrupted.</p></li></ul><p>These are not values.</p><p>They are <strong>preconditions for having values at all</strong>.</p><p>If they fail, asking whether a future is “good” or “bad” is a category error. It is like asking whether a sentence that does not parse is true.</p><div><hr></div><h2>6. Why kernel‑destroying futures are undefined</h2><p>The formalism makes a simple but important claim:</p><p>An agent cannot meaningfully evaluate a future in which the evaluator itself no longer exists as an evaluator.</p><p>This is not a moral prohibition.<br>It is not a safety rule.</p><p>It is a typing failure.</p><p>The agent is not <em>forbidden</em> from self‑destruction.<br>It simply cannot treat self‑destruction as an option in deliberation.</p><div><hr></div><h2>7. Why the main theorem is boring on purpose</h2><p>Once admissibility is defined this way, stability follows automatically.</p><p>If the agent can only choose among evaluable self‑modifications, then it will never choose one that makes evaluation impossible.</p><p>The main theorem in the paper formalizes this bookkeeping step.</p><p>This is why the proof is trivial.</p><p>All the work is done by the definitions.</p><div><hr></div><h2>8. Conservative agents and stasis</h2><p>A sound but conservative verifier may reject <em>all</em> proposed self‑modifications.</p><p>The agent may become reflectively static.</p><p>This is not treated as a failure.</p><p>It is the expected equilibrium of a conservative safety discipline.</p><p>A static agent can still act, plan, reason, and operate in the world.<br>What it cannot do is rewrite the machinery that makes it a coherent agent in the first place.</p><p>Axionic Alignment prefers stasis to self‑corruption.</p><div><hr></div><h2>9. What this does <em>not</em> guarantee</h2><p>At this point, the model still contains:</p><ul><li><p>no other agents,</p></li><li><p>no harm operator,</p></li><li><p>no notion of coercion,</p></li><li><p>no human values.</p></li></ul><p>That is why a reflectively stable agent can still pursue goals humans would consider dangerous or indifferent.</p><p>This is not an endorsement.<br>It is a limitation of the model.</p><p>Integrity is necessary for ethics.<br>It is not sufficient.</p><div><hr></div><h2>10. Why this layering matters</h2><p>Most alignment proposals try to solve everything at once:</p><ul><li><p>integrity,</p></li><li><p>values,</p></li><li><p>incentives,</p></li><li><p>safety,</p></li><li><p>governance.</p></li></ul><p>They fail because later assumptions undermine earlier ones.</p><p>Axionic Alignment proceeds in layers:</p><ol><li><p><strong>Alignment I</strong> — make agency stable.</p></li><li><p><strong>Alignment II</strong> — make stability enforceable in real systems.</p></li><li><p><strong>Alignment III</strong> — constrain how stable agents may treat each other.</p></li></ol><p>Only in the third layer does it make sense to talk about harm, coercion, or ethical injunctions.</p><div><hr></div><h2>Postscript</h2><p>You should now be able to read <em>Axionic Alignment I</em> without asking it to do more than it claims.</p><p>It does not define values.<br>It does not ensure benevolence.</p><p>It draws a single boundary: between evaluable and non-evaluable futures.</p><p>Everything beyond that boundary comes later.</p>
    </article>

    <!-- KaTeX JavaScript -->
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
    <script>
        // Find all LaTeX blocks and render them
        document.querySelectorAll('.latex-rendered').forEach(el => {
            const dataAttrs = el.getAttribute('data-attrs');
            if (dataAttrs) {
                try {
                    const attrs = JSON.parse(dataAttrs);
                    const expr = attrs.persistentExpression;
                    if (expr) {
                        katex.render(expr, el, {
                            displayMode: true,
                            throwOnError: false,
                            trust: true
                        });
                    }
                } catch (e) {
                    console.error('Error rendering LaTeX:', e);
                }
            }
        });
    </script>
</body>
</html>
