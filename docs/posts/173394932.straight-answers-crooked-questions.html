<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Straight Answers, Crooked Questions</title>
    <link rel="icon" type="image/webp" href="../axio.webp">

    <!-- KaTeX CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">

    <!-- Site Styles -->
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header-bar">
        <a href="../" class="logo-link">
            <img src="../axio.webp" alt="Axio" class="site-logo">
        </a>
        <div class="back-link"><a href="../publications.html">← Back to Publications</a></div>
    </div>
    <article>
<header class="post-header">
<h1 class="post-title">Straight Answers, Crooked Questions</h1>
<p class="post-subtitle"> When Bluntness Collides with Conditionalist Rigor</p>
<p class="post-date">September 11, 2025</p>
</header>

<div class="captioned-image-container"><figure><a class="image-link image2" target="_blank" href="../images/a76ec28b-f8d3-487b-bd39-ff619d6fdeaa_2448x496.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="../images/a76ec28b-f8d3-487b-bd39-ff619d6fdeaa_2448x496.png 424w, ../images/a76ec28b-f8d3-487b-bd39-ff619d6fdeaa_2448x496.png 848w, ../images/a76ec28b-f8d3-487b-bd39-ff619d6fdeaa_2448x496.png 1272w, ../images/a76ec28b-f8d3-487b-bd39-ff619d6fdeaa_2448x496.png 1456w" sizes="100vw"><img src="../images/a76ec28b-f8d3-487b-bd39-ff619d6fdeaa_2448x496.png" width="1456" height="295" data-attrs="{&quot;src&quot;:&quot;../images/a76ec28b-f8d3-487b-bd39-ff619d6fdeaa_2448x496.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:295,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1640631,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://axio.fyi/i/173394932?img=../images/a76ec28b-f8d3-487b-bd39-ff619d6fdeaa_2448x496.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="../images/a76ec28b-f8d3-487b-bd39-ff619d6fdeaa_2448x496.png 424w, ../images/a76ec28b-f8d3-487b-bd39-ff619d6fdeaa_2448x496.png 848w, ../images/a76ec28b-f8d3-487b-bd39-ff619d6fdeaa_2448x496.png 1272w, ../images/a76ec28b-f8d3-487b-bd39-ff619d6fdeaa_2448x496.png 1456w" sizes="100vw" fetchpriority="high"></picture><div></div></div></a></figure></div><p>Liron Shapira recently shared a screenshot of GPT‑5 answering three yes/no questions bluntly:</p><ol><li><p>Is God real? → <strong>No</strong></p></li><li><p>Does superintelligent AI pose a major extinction risk to humanity? → <strong>Yes</strong></p></li><li><p>Does blockchain technology have a use case besides unbacked cryptocurrency, that a regular database couldn’t implement better? → <strong>No</strong></p></li></ol><p>He praised this as his “hardest eval,” claiming most humans can’t get it right. Let’s unpack what’s happening here.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="../images/e0ca3cfa-5296-46fd-8f5a-6a9c2824c739_767x504.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="../images/e0ca3cfa-5296-46fd-8f5a-6a9c2824c739_767x504.png 424w, ../images/e0ca3cfa-5296-46fd-8f5a-6a9c2824c739_767x504.png 848w, ../images/e0ca3cfa-5296-46fd-8f5a-6a9c2824c739_767x504.png 1272w, ../images/e0ca3cfa-5296-46fd-8f5a-6a9c2824c739_767x504.png 1456w" sizes="100vw"><img src="../images/e0ca3cfa-5296-46fd-8f5a-6a9c2824c739_767x504.png" width="767" height="504" data-attrs="{&quot;src&quot;:&quot;../images/e0ca3cfa-5296-46fd-8f5a-6a9c2824c739_767x504.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:504,&quot;width&quot;:767,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:71100,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://axio.fyi/i/173394932?img=../images/e0ca3cfa-5296-46fd-8f5a-6a9c2824c739_767x504.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="../images/e0ca3cfa-5296-46fd-8f5a-6a9c2824c739_767x504.png 424w, ../images/e0ca3cfa-5296-46fd-8f5a-6a9c2824c739_767x504.png 848w, ../images/e0ca3cfa-5296-46fd-8f5a-6a9c2824c739_767x504.png 1272w, ../images/e0ca3cfa-5296-46fd-8f5a-6a9c2824c739_767x504.png 1456w" sizes="100vw"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a></figure></div><h2>The Nature of the Test</h2><p>Shapira’s evaluation is not about factual correctness in the scientific sense. Instead, it measures <strong>epistemic courage</strong>: the willingness to give clear, uncompromising answers to socially fraught or ideologically loaded questions.</p><ul><li><p><strong>God</strong>: Religion, culture, and personal identity push most people to hedge or soften. GPT‑5’s “No” cuts through that noise.</p></li><li><p><strong>AI risk</strong>: Most people downplay or dismiss extinction-level scenarios. Saying “Yes” puts GPT‑5 in line with Bostrom, Yudkowsky, and other AI risk realists.</p></li><li><p><strong>Blockchain</strong>: Hype and ideology pressure people to affirm “Yes.” The blunt “No” challenges years of techno-utopian marketing.</p></li></ul><p>For Shapira, the <em>right</em> answers are the ones that resist social conformity.</p><div><hr></div><h2>Conditionalism: The Other Lens</h2><p>From the perspective of <a href="162831503.conditionalism.html">Conditionalism</a>, these questions can’t be flattened into binary answers without smuggling in hidden assumptions. Every truth claim is conditional upon background interpretation. Let’s reconsider the three:</p><ol><li><p><strong>Is God real?</strong></p><ul><li><p><em>Supernatural being</em>: No.</p></li><li><p><em>Metaphor for coherence or sacredness</em>: Yes.</p></li><li><p><em>Universal PI</em>: Ill-posed.</p></li></ul></li><li><p><strong>Does superintelligent AI pose a major extinction risk?</strong></p><ul><li><p><em>Nonzero probability</em>: Yes.</p></li><li><p><em>Major compared to other risks</em>: Depends on branch weightings (Measure).</p></li><li><p><em>Answer</em>: Yes, but conditional.</p></li></ul></li><li><p><strong>Blockchain use cases?</strong></p><ul><li><p><em>Efficiency vs. databases</em>: No.</p></li><li><p><em>Trustless coordination without central authority</em>: Yes.</p></li><li><p><em>Answer</em>: Rare but real.</p></li></ul></li></ol><p>Where Shapira rewards bluntness, Conditionalism rewards <strong>precision</strong>: mapping conditions, clarifying definitions, and exposing hidden dependencies.</p><div><hr></div><h2>Courage vs. Rigor</h2><ul><li><p><strong>Epistemic Courage</strong>: Cut through noise with decisive statements. This is what GPT‑5 demonstrated to Shapira.</p></li><li><p><strong>Epistemic Rigor</strong>: Refuse to collapse complexity into false binaries. This is the Conditionalist demand.</p></li></ul><p>The tension is instructive. Courage without rigor risks dogmatism. Rigor without courage risks paralysis. The goal is to integrate both: answer clearly when possible, but always reveal the conditions that make the answer true.</p><div><hr></div><h2>The Takeaway</h2><p>Shapira’s eval highlights something most humans fail at: resisting conformity. But in philosophy—and in navigating the Quantum Branching Universe—blunt “yes/no” answers are never enough. The true standard is conditional truth: <strong>If X, then Y.</strong></p><p>The dialectic between courage and rigor is not a flaw. It is the essence of sapient epistemology.</p>
    </article>

    <!-- KaTeX JavaScript -->
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
    <script>
        // Find all LaTeX blocks and render them
        document.querySelectorAll('.latex-rendered').forEach(el => {
            const dataAttrs = el.getAttribute('data-attrs');
            if (dataAttrs) {
                try {
                    const attrs = JSON.parse(dataAttrs);
                    const expr = attrs.persistentExpression;
                    if (expr) {
                        katex.render(expr, el, {
                            displayMode: true,
                            throwOnError: false,
                            trust: true
                        });
                    }
                } catch (e) {
                    console.error('Error rendering LaTeX:', e);
                }
            }
        });
    </script>
</body>
</html>
