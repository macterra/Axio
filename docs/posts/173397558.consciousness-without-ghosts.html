<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Consciousness Without Ghosts</title>
    <link rel="icon" type="image/webp" href="../axio.webp">

    <!-- KaTeX CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">

    <!-- Site Styles -->
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header-bar">
        <a href="../index.html" class="logo-link">
            <img src="../axio.webp" alt="Axio" class="site-logo">
        </a>
        <div class="back-link"><a href="../index.html">← Back to Index</a></div>
    </div>
    <article>
<header class="post-header">
<h1 class="post-title">Consciousness Without Ghosts</h1>
<p class="post-subtitle">Defending the Agency-Model Theory of Consciousness</p>
</header>

<div class="captioned-image-container"><figure><a class="image-link image2" target="_blank" href="https://substackcdn.com/image/fetch/$s_!Nwv0!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f1c3e78-f31d-4155-a025-8a5f8d97eb55_2448x496.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Nwv0!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f1c3e78-f31d-4155-a025-8a5f8d97eb55_2448x496.png 424w, https://substackcdn.com/image/fetch/$s_!Nwv0!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f1c3e78-f31d-4155-a025-8a5f8d97eb55_2448x496.png 848w, https://substackcdn.com/image/fetch/$s_!Nwv0!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f1c3e78-f31d-4155-a025-8a5f8d97eb55_2448x496.png 1272w, https://substackcdn.com/image/fetch/$s_!Nwv0!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f1c3e78-f31d-4155-a025-8a5f8d97eb55_2448x496.png 1456w" sizes="100vw"><img src="https://substack-post-media.s3.amazonaws.com/public/images/8f1c3e78-f31d-4155-a025-8a5f8d97eb55_2448x496.png" width="1456" height="295" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8f1c3e78-f31d-4155-a025-8a5f8d97eb55_2448x496.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:295,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2125378,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://axio.fyi/i/173397558?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f1c3e78-f31d-4155-a025-8a5f8d97eb55_2448x496.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Nwv0!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f1c3e78-f31d-4155-a025-8a5f8d97eb55_2448x496.png 424w, https://substackcdn.com/image/fetch/$s_!Nwv0!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f1c3e78-f31d-4155-a025-8a5f8d97eb55_2448x496.png 848w, https://substackcdn.com/image/fetch/$s_!Nwv0!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f1c3e78-f31d-4155-a025-8a5f8d97eb55_2448x496.png 1272w, https://substackcdn.com/image/fetch/$s_!Nwv0!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f1c3e78-f31d-4155-a025-8a5f8d97eb55_2448x496.png 1456w" sizes="100vw" fetchpriority="high"></picture><div></div></div></a></figure></div><p>When <em><a href="173236908.mirrors-of-the-mind.html">Mirrors of the Mind</a></em> was published, several likely objections became clear. Here are concise responses, ready for reference in discussion or as a follow-up post.</p><div><hr></div><h2>Objection 1: <em>“But why this feel, rather than some other?”</em></h2><p><strong>Reply:</strong> The structure of qualia follows from the structure of the self-model. Red looks the way it does because the visual system evolved to partition inputs in that way for efficient discrimination. Pain feels the way it does because its function is to demand aversion. The “what-it-is-like” is not arbitrary; it is determined by how the model encodes information for action.</p><div><hr></div><h2>Objection 2: <em>“Who is the subject that experiences the model outputs?”</em></h2><p><strong>Reply:</strong> There is no inner homunculus. The self-model itself is the subject. Asking “who” experiences qualia is like asking “where” computation really happens. The perspective is built into the model’s operation.</p><div><hr></div><h2>Objection 3: <em>“But isn’t consciousness non-reducible, fundamentally different from computation?”</em></h2><p><strong>Reply:</strong> Computation is substrate-independent. Consciousness is, too. In both cases, demanding a deeper ontological “stuff” is a mistake. They are informational processes, not metaphysical substances.</p><div><hr></div><h2>Objection 4: <em>“Your theory is unfalsifiable.”</em></h2><p><strong>Reply:</strong> It makes testable predictions: alter or impair the self-model and phenomenology changes. Depersonalization, anosognosia, and body-schema disturbances already support this. The richer the self-model, the richer the reported qualia.</p><div><hr></div><h2>Objection 5: <em>“Wouldn’t this mean AI can be conscious?”</em></h2><p><strong>Reply:</strong> Yes—if an AI builds and uses a generative self-model to regulate its own actions, it would meet the criteria. The question is not biology versus silicon, but whether agency requires and runs a self-model.</p><div><hr></div><h2>Objection 6: <em>“Isn’t this just illusionism in disguise?”</em></h2><p><strong>Reply:</strong> Not quite. Illusionism says consciousness doesn’t exist, only the illusion of it. AMT says consciousness is real, but what it <em>is</em> is the operation of an agent’s self-model. The “hard problem” is the illusion, not consciousness itself.</p><div><hr></div><h2>Closing Note</h2><p>The <em>Agency-Model Theory</em> doesn’t deny subjectivity—it explains it. Experience is what it looks like from the inside when an agent models itself. The “hard problem” dissolves once we stop chasing a metaphysical ghost.</p>
    </article>

    <!-- KaTeX JavaScript -->
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
    <script>
        // Find all LaTeX blocks and render them
        document.querySelectorAll('.latex-rendered').forEach(el => {
            const dataAttrs = el.getAttribute('data-attrs');
            if (dataAttrs) {
                try {
                    const attrs = JSON.parse(dataAttrs);
                    const expr = attrs.persistentExpression;
                    if (expr) {
                        katex.render(expr, el, {
                            displayMode: true,
                            throwOnError: false,
                            trust: true
                        });
                    }
                } catch (e) {
                    console.error('Error rendering LaTeX:', e);
                }
            }
        });
    </script>
</body>
</html>
