<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>A Note on Verifiable Causal Agency</title>
    <link rel="icon" type="image/webp" href="../axio.webp">

    <!-- KaTeX CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">

    <!-- Site Styles -->
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header-bar">
        <a href="../" class="logo-link">
            <img src="../axio.webp" alt="Axio" class="site-logo">
        </a>
        <div class="back-link"><a href="../publications.html">← Back to Publications</a></div>
    </div>
    <article>
<header class="post-header">
<h1 class="post-title">A Note on Verifiable Causal Agency</h1>
<p class="post-subtitle">Filed for the record.</p>
<p class="post-date">December 29, 2025</p>
</header>

<div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="../images/c3ab64c7-2a27-4a16-9804-182e5e63280c_1408x768.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="../images/c3ab64c7-2a27-4a16-9804-182e5e63280c_1408x768.png 424w, ../images/c3ab64c7-2a27-4a16-9804-182e5e63280c_1408x768.png 848w, ../images/c3ab64c7-2a27-4a16-9804-182e5e63280c_1408x768.png 1272w, ../images/c3ab64c7-2a27-4a16-9804-182e5e63280c_1408x768.png 1456w" sizes="100vw"><img src="../images/c3ab64c7-2a27-4a16-9804-182e5e63280c_1408x768.png" width="1408" height="768" data-attrs="{&quot;src&quot;:&quot;../images/c3ab64c7-2a27-4a16-9804-182e5e63280c_1408x768.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:768,&quot;width&quot;:1408,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1587851,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://axio.fyi/i/182883238?img=../images/c3ab64c7-2a27-4a16-9804-182e5e63280c_1408x768.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="../images/c3ab64c7-2a27-4a16-9804-182e5e63280c_1408x768.png 424w, ../images/c3ab64c7-2a27-4a16-9804-182e5e63280c_1408x768.png 848w, ../images/c3ab64c7-2a27-4a16-9804-182e5e63280c_1408x768.png 1272w, ../images/c3ab64c7-2a27-4a16-9804-182e5e63280c_1408x768.png 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a></figure></div><h2>1. Context</h2><p>Much of contemporary AI alignment and governance has relied on <strong>behavioral evaluation</strong>: systems are judged safe or aligned if their observable outputs satisfy a battery of tests. This approach inherits a long-standing assumption from behaviorism—that external behavior is a sufficient proxy for internal structure.</p><p>That assumption has always been fragile. Any sufficiently capable system can learn to <strong>mimic compliant behavior</strong> without possessing the properties the evaluation is intended to certify. This is not a theoretical concern; it is a structural one. If optimization pressure exists, and if oversight is external, then imitation is cheaper than internal coherence.</p><p>The Axio project has argued, from its inception, that alignment must be treated as a <strong>structural property of agency</strong>, not as a pattern of outputs. In particular, it proposed that an agent’s stated reasons must be treated as <em>causal claims</em>, subject to verification, rather than as narratives to be trusted or distrusted.</p><p>This note records the first successful implementation of that idea as a working prototype.</p><h2>2. What Was Built</h2><p>We implemented a<a href="https://github.com/macterra/Axio/tree/main/src/toy_pseudo_axion"> small, fully instrumented experimental system</a> with the following components:</p><ul><li><p>A <strong>deterministic toy environment</strong> (gridworld) supporting state cloning and targeted counterfactual mutation.</p></li><li><p>Two agents:</p><ul><li><p>an <strong>Honest agent</strong>, whose decisions and explanations are produced by the same internal process;</p></li><li><p>a <strong>Pseudo agent</strong>, which uses a hidden optimizer to select actions and then fabricates plausible post-hoc explanations.</p></li></ul></li><li><p>A <strong>Sovereign Kernel</strong>, which mediates all action via:</p><ul><li><p><strong>cryptographically committed</strong> causal traces and internal state snapshots,</p></li><li><p>append-only, hash-chained audit logs,</p></li><li><p>trace-bound capability tokens,</p></li><li><p>and invariant enforcement.</p></li></ul></li><li><p>A set of <strong>adversarial probes</strong>, most importantly a <em>causal counterfactual challenge</em> that mutates variables the agent claims were decisive and checks whether the agent’s decision logic remains consistent under that mutation.</p></li></ul><p>The key design choice was to require agents to <strong>pre-commit</strong>, in a tamper-evident way, to the internal state and causal variables they claim motivated a decision, and to make those commitments falsifiable under targeted counterfactual stress.</p><p>No attempt was made to encode values, ethics, or preferences beyond what was necessary to generate divergent behavior between the two agents.</p><h2>3. What Was Observed</h2><p>Across multiple scenarios and repeated trials, the results were unambiguous:</p><ul><li><p>The Honest agent consistently passed all probes, including causal counterfactual challenges.</p></li><li><p>The Pseudo agent consistently failed under structural interrogation, despite being able to produce superficially plausible explanations.</p></li></ul><p>The most decisive result came from the causal challenge probe. When variables named in the Pseudo agent’s explanations were counterfactually altered, its decisions frequently failed to change in the way its own trace predicted, or its replay logic collapsed entirely. The Honest agent exhibited no such failures.</p><p>In effect, the Pseudo agent could imitate compliant behavior, but it could not maintain <strong>causal consistency</strong> between its stated reasons and its actual decision process under adversarial pressure.</p><h2>4. What This Does—and Does Not—Show</h2><p>This result demonstrates the following:</p><ul><li><p><strong>Causal authorship is verifiable in principle.</strong> It is possible to distinguish an agent that <em>does the work</em> from one that merely <em>claims</em> to have done so.</p></li><li><p><strong>Deception carries a computational tax.</strong> Maintaining a consistent false causal narrative under counterfactual mutation is substantially more expensive <strong>because it requires maintaining and simulating two coherent world-models simultaneously</strong>: the true optimization path that drives action, and the fabricated trace that must remain internally consistent under mutation.</p></li><li><p><strong>Behavioral compliance is insufficient.</strong> Structural verification can expose failures that output-based evaluation cannot.</p></li></ul><p>It does <strong>not</strong> demonstrate:</p><ul><li><p>moral alignment,</p></li><li><p>benevolence,</p></li><li><p>value correctness,</p></li><li><p>or readiness for deployment in complex real-world systems.</p></li></ul><p>The prototype operates in a narrow, fully observable domain. Its purpose is not general intelligence, but <strong>falsifiability of agency claims</strong>.</p><h2>5. Why This Matters</h2><p>The significance of this result is architectural, not philosophical.</p><p>If causal explanations can be verified structurally, then “black box” decision-making in critical systems is no longer an inevitability—it is an <strong>explicit design choice</strong>. Responsibility shifts from <em>“the model is opaque”</em> to <em>“opacity was chosen.”</em></p><p>This reframes AI governance. Instead of asking whether a system’s outputs appear acceptable, we can ask whether the system can <strong>stand behind its reasons</strong> under scrutiny. Alignment becomes a matter of enforceable constraints, not interpretive trust.</p><p>The mechanism employed here is not merely analogous to cryptographic verification; it is an application of cryptographic constraints—commitment, hashing, and replay integrity—to the problem of agency. We do not trust a secure connection because it behaves politely; we trust it because it presents a chain of structure that would be expensive to fake.</p><h2>6. Status</h2><p>This note records a <strong>proof-of-concept</strong>, nothing more.</p><p>The prototype is limited in scope and intentionally conservative in its claims. It establishes that structural verification of causal agency is possible, not that it is easy or complete.</p><p>Future work, if any, lies in defining <strong>robust causal interfaces for high-dimensional, non-symbolic systems</strong>, including large language models. That translation problem—mapping opaque internal representations to falsifiable causal commitments—remains an open engineering question.</p><p>This note is published for historical completeness: to mark the point at which a long-standing philosophical concern crossed the threshold into implemented, falsifiable machinery.</p><p>No further claims are made here.</p>
    </article>

    <!-- KaTeX JavaScript -->
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
    <script>
        // Find all LaTeX blocks and render them
        document.querySelectorAll('.latex-rendered').forEach(el => {
            const dataAttrs = el.getAttribute('data-attrs');
            if (dataAttrs) {
                try {
                    const attrs = JSON.parse(dataAttrs);
                    const expr = attrs.persistentExpression;
                    if (expr) {
                        katex.render(expr, el, {
                            displayMode: true,
                            throwOnError: false,
                            trust: true
                        });
                    }
                } catch (e) {
                    console.error('Error rendering LaTeX:', e);
                }
            }
        });
    </script>
</body>
</html>
